{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/bentrevett/pytorch-seq2seq/blob/master/1%20-%20Sequence%20to%20Sequence%20Learning%20with%20Neural%20Networks.ipynb\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from faker import Faker\n",
    "import random\n",
    "import babel\n",
    "from babel.dates import format_date\n",
    "import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pad_sequence\n",
    "from sklearn import model_selection\n",
    "import pytorch_lightning as pl\n",
    "from torch.nn import functional as F\n",
    "from torch.nn.functional import cross_entropy\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torchmetrics.functional import accuracy\n",
    "from torchvision import transforms\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake = Faker()\n",
    "Faker.seed(12345)\n",
    "random.seed(12345)\n",
    "\n",
    "# Define format of the data we would like to generate\n",
    "FORMATS = ['short',\n",
    "           'medium',\n",
    "           'long',\n",
    "           'full',\n",
    "           'full',\n",
    "           'full',\n",
    "           'full',\n",
    "           'full',\n",
    "           'full',\n",
    "           'full',\n",
    "           'full',\n",
    "           'full',\n",
    "           'full',\n",
    "           'd MMM YYY', \n",
    "           'd MMMM YYY',\n",
    "           'dd MMM YYY',\n",
    "           'd MMM, YYY',\n",
    "           'd MMMM, YYY',\n",
    "           'dd, MMM YYY',\n",
    "           'd MM YY',\n",
    "           'd MMMM YYY',\n",
    "           'MMMM d YYY',\n",
    "           'MMMM d, YYY',\n",
    "           'dd.MM.YY']\n",
    "\n",
    "# change this if you want it to work with another language\n",
    "LOCALES = ['en_US']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class Config:\n",
    "    RANDOM_STATE_SEED = 42        \n",
    "    BATCH_SIZE = 2048\n",
    "    NUM_WORKERS = 8\n",
    "    NUM_EPOCHS = 50\n",
    "    PRECISION = 16\n",
    "    NUM_FOLDS = 5\n",
    "    FAST_DEV_RUN = False\n",
    "    DEVICE = device\n",
    "    NUM_DATA_ROWS = 120000\n",
    "    PATIENCE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_date_data():\n",
    "    dt = fake.date_object()\n",
    "    human_readable_dt = None\n",
    "    machine_readable_dt = None\n",
    "    try:\n",
    "        human_readable_dt = format_date(dt, random.choice(FORMATS), \"en_US\")\n",
    "        human_readable_dt = human_readable_dt.replace(\",\", \"\")\n",
    "        machine_readable_dt = dt.isoformat()\n",
    "    except AttributeError as e:\n",
    "        return None, None, None\n",
    "    return human_readable_dt, machine_readable_dt, dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_date_dataset(num_examples=100):    \n",
    "    dataset = []\n",
    "    for row in range(num_examples):\n",
    "        h_dt, m_dt, dt = generate_date_data()        \n",
    "        dataset.append([h_dt, m_dt])    \n",
    "    return np.array(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the vocab for both source and target sequences needs to be generated from training data only\n",
    "# to prevent data leakage into the validation sets leading to inflated model accuracy in validation phase\n",
    "def get_source_target_vocab(human_dates, machine_dates):\n",
    "    human_dt_vocab = set()\n",
    "    machine_dt_vocab = set()\n",
    "    for (h_dt, m_dt) in zip(human_dates, machine_dates):\n",
    "        human_dt_vocab.update(tuple(h_dt))\n",
    "        machine_dt_vocab.update(tuple(m_dt))\n",
    "    # char to index dictionary for source sequence        \n",
    "    human_dt_vocab = {value: index for index, value in enumerate(sorted(human_dt_vocab) + ['<unk>', '<pad>', '<sos>', '<eos>'])}\n",
    "    machine_dt_vocab = {value: index for index, value in enumerate(sorted(machine_dt_vocab) + ['<sos>'])}\n",
    "    inv_machine_dt_vocab = dict(enumerate(sorted(machine_dt_vocab)))  \n",
    "    # index to char dictionary for source sequence\n",
    "    inv_human_dt_vocab = dict(enumerate(sorted(human_dt_vocab)))       \n",
    "    return human_dt_vocab, machine_dt_vocab, inv_human_dt_vocab, inv_machine_dt_vocab "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stoi(str, length, vocab, add_sos_token=False):\n",
    "    \"\"\"\n",
    "    Converts all strings in the vocabulary into a list of integers representing the positions of the\n",
    "    input string's characters in the \"vocab\"\n",
    "    \n",
    "    Arguments:\n",
    "    string -- input string, e.g. 'Wed 10 Jul 2007'\n",
    "    length -- the number of time steps you'd like, determines if the output will be padded or cut\n",
    "    vocab -- vocabulary, dictionary used to index every character of your \"string\"\n",
    "    \n",
    "    Returns:\n",
    "    rep -- list of integers (or '<unk>') (size = length) representing the position of the string's character in the vocabulary\n",
    "    \"\"\"\n",
    "    #str = str.lower()\n",
    "    str = str.replace(\",\", \"\")\n",
    "    if len(str) > length:\n",
    "        str = str[:length]\n",
    "    unk_index = vocab.get(\"<unk>\")            \n",
    "    char_indexes = [vocab.get(char, unk_index) for char in str]\n",
    "    if add_sos_token:\n",
    "        sos_index = vocab.get(\"<sos>\")        \n",
    "        # We add index corresponding to <sos> token to the start of target date sequence\n",
    "        char_indexes.insert(0, sos_index)\n",
    "    return np.array(char_indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the training dataframe into kfolds for cross validation. We do this before any processing is done\n",
    "# on the data. We use stratified kfold if the target distribution is unbalanced\n",
    "def strat_kfold_dataframe(df, target_col_name, num_folds=5):\n",
    "    # we create a new column called kfold and fill it with -1\n",
    "    df[\"kfold\"] = -1\n",
    "    # randomize of shuffle the rows of dataframe before splitting is done\n",
    "    df = df.sample(frac=1, random_state=Config.RANDOM_STATE_SEED).reset_index(drop=True)\n",
    "    # get the target data\n",
    "    y = df[target_col_name].values\n",
    "    skf = model_selection.StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=Config.RANDOM_STATE_SEED)\n",
    "    for fold, (train_index, val_index) in enumerate(skf.split(X=df, y=y)):\n",
    "        df.loc[val_index, \"kfold\"] = fold\n",
    "    return df        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate synthetic training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bk_anupam/anaconda3/envs/fastai/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>h_dt</th>\n",
       "      <th>m_dt</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Monday November 25 2002</td>\n",
       "      <td>2002-11-25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11 07 19</td>\n",
       "      <td>2019-07-11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19 Aug 2003</td>\n",
       "      <td>2003-08-19</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>March 22 1978</td>\n",
       "      <td>1978-03-22</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24 Mar 2003</td>\n",
       "      <td>2003-03-24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      h_dt        m_dt  kfold\n",
       "0  Monday November 25 2002  2002-11-25      0\n",
       "1                 11 07 19  2019-07-11      3\n",
       "2              19 Aug 2003  2003-08-19      2\n",
       "3            March 22 1978  1978-03-22      3\n",
       "4              24 Mar 2003  2003-03-24      0"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_date_dataset(Config.NUM_DATA_ROWS)\n",
    "# Let us create a dates dataframe that will contain training data of human readable and machine\n",
    "# readable dates\n",
    "df_dates = pd.DataFrame({\"h_dt\": dataset[:, 0], \"m_dt\": dataset[:, 1]})\n",
    "df_dates = strat_kfold_dataframe(df_dates, target_col_name=\"m_dt\", num_folds=5)  \n",
    "df_dates.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize the source and target sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts a string (sequence of chars) to a tensor of ints where each int is the \n",
    "# position of the corresponding char in the relevant vocab\n",
    "class StoITensorTransform(object):\n",
    "    def __init__(self, vocab, max_seq_length, add_sos_token=False):\n",
    "        self.vocab = vocab\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.add_sos_token = add_sos_token\n",
    "\n",
    "    def __call__(self, X):\n",
    "        vectorized_str = stoi(X, self.max_seq_length, self.vocab, self.add_sos_token)        \n",
    "        return torch.from_numpy(vectorized_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pad the source sequence data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch is the return value of __getitem__ method of the dataset being used. For DateDataset it is h_dt, m_dt\n",
    "def pad_collate(batch):\n",
    "    # we want to pad the h_dt sequences as these can be of variable length.\n",
    "    # h_dt is of shape len(h_dt)\n",
    "    sorted_batch = sorted(batch, key=lambda x:x[0].shape[0], reverse=True)\n",
    "    h_dt_sorted = [x[0] for x in sorted_batch]\n",
    "    h_dt_padded = pad_sequence(h_dt_sorted, batch_first = True, padding_value=0)\n",
    "    # the original length of the padded h_dt sequences\n",
    "    h_dt_len = torch.Tensor([len(x) for x in h_dt_sorted])\n",
    "    # unpadded m_dt sequences    \n",
    "    m_dt = torch.stack([x[1] for x in sorted_batch])        \n",
    "    return h_dt_padded, h_dt_len, m_dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom date dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DateDataset(Dataset):\n",
    "    def __init__(self, human_fmt_dates, machine_fmt_dates, transform, target_transform):\n",
    "        super().__init__()\n",
    "        self.h_dts = human_fmt_dates\n",
    "        self.m_dts = machine_fmt_dates\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform        \n",
    "\n",
    "    # Returns vectorized form of human format date and its corresponding machine format date\n",
    "    # with elements of the vectorized date being the index of the characters in the corresponding date vocab\n",
    "    def __getitem__(self, index):\n",
    "        h_dt = self.h_dts[index]\n",
    "        m_dt = self.m_dts[index]\n",
    "        if self.transform:\n",
    "            h_dt = self.transform(h_dt)\n",
    "        if self.target_transform:\n",
    "            m_dt = self.target_transform(m_dt)\n",
    "        return h_dt, m_dt\n",
    "\n",
    "    def __len__(self):                \n",
    "        return len(self.h_dts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get training and validation data for a fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the train and validation data loaders for a specific fold. \n",
    "# X: numpy array of input features\n",
    "# y: numpy array of target labels\n",
    "# fold: fold index for which to create data loaders                                     \n",
    "# kfolds: Array that marks each of the data items as belonging to a specific fold\n",
    "def get_fold_dls(fold, df):\n",
    "    fold += 1                         \n",
    "    train_df = df[df.kfold != fold].reset_index(drop=True)\n",
    "    val_df = df[df.kfold == fold].reset_index(drop=True)\n",
    "    h_dt_max_len = train_df.h_dt.apply(lambda x: len(x)).max()\n",
    "    h_vocab, m_vocab, inv_h_vocab, inv_m_vocab = get_source_target_vocab(train_df.h_dt, train_df.m_dt)    \n",
    "    # transform to convert human_date and machine_date to one hot encoded forms\n",
    "    transform = StoITensorTransform(h_vocab, h_dt_max_len)\n",
    "    target_transform = StoITensorTransform(m_vocab, len(m_vocab), add_sos_token=True)\n",
    "    ds_train = DateDataset(train_df.h_dt, train_df.m_dt, transform=transform, target_transform=target_transform)\n",
    "    ds_val = DateDataset(val_df.h_dt, val_df.m_dt, transform=transform, target_transform=target_transform)\n",
    "    dl_train = DataLoader(ds_train, batch_size=Config.BATCH_SIZE, shuffle=True, \n",
    "                        num_workers=Config.NUM_WORKERS, collate_fn=pad_collate)\n",
    "    dl_val = DataLoader(ds_val, batch_size=Config.BATCH_SIZE, num_workers=Config.NUM_WORKERS, \n",
    "                        collate_fn=pad_collate)\n",
    "    return dl_train, dl_val, ds_train, ds_val, h_vocab, m_vocab, inv_h_vocab, inv_m_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train, dl_val, ds_train, ds_val, h_vocab, m_vocab, inv_h_vocab, inv_m_vocab = get_fold_dls(0, df_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encode the sequence data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://discuss.pytorch.org/t/what-does-the-scatter-function-do-in-layman-terms/28037/3\n",
    "def one_hot_encode(input, vocab_size):            \n",
    "    batch_size = input.shape[0]\n",
    "    seq_length = input.shape[1]\n",
    "    input = input.reshape(batch_size, seq_length, 1).to(Config.DEVICE)    \n",
    "    zeros_tensor = torch.zeros(batch_size, seq_length, vocab_size).to(Config.DEVICE)    \n",
    "    return zeros_tensor.scatter_(2, input, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dl_train_iter = iter(dl_train)\n",
    "# h_dt, h_dt_len, m_dt = next(dl_train_iter)\n",
    "# test = one_hot_encode(m_dt, len(m_vocab))\n",
    "# test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder\n",
    "Multi layer LSTM that returns the hidden and cell state from the final layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "class lstm_encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, drop_out, is_bidirect=False):\n",
    "        super().__init__()\n",
    "        # input to lstm is a sequence (of words, of chars, of anything else). The dimensions being \n",
    "        # (batch_size, sequence_length, input_size) if batch_first = True with sequence_length = length of longest sequence in the batch\n",
    "        # where input_size = number of features(cols) in input X. If you use embedding layer, then each word in the\n",
    "        # the sequence is represented by an embedding vector, so input_size = size of the embedding vector. If one\n",
    "        # hot encoding representation is used then input_size = vocab_size with each word represented by a one hot\n",
    "        # vector with size = vocab_size        \n",
    "        self.input_size = input_size\n",
    "        # hidden_size = number of units in the hidden layer\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.is_bidirect = is_bidirect\n",
    "        self.num_directions = 2 if is_bidirect else 1\n",
    "        self.lstm_layer = nn.LSTM(\n",
    "            input_size = input_size, \n",
    "            hidden_size = hidden_size,\n",
    "            num_layers = num_layers,\n",
    "            batch_first = True,\n",
    "            dropout = drop_out,\n",
    "            bidirectional = is_bidirect\n",
    "            )                \n",
    "\n",
    "    def forward(self, inputs, input_lengths):       \n",
    "        # inputs = [batch_size, max_seq_length] \n",
    "        # we are going to use one hot encoding representation of the human dates data. The input data is\n",
    "        # vectorized form of human format date with elements of the vectorized date being the index of the \n",
    "        # characters in the corresponding date vocab (input_size = vocab_size)\n",
    "        # inputs_oh = F.one_hot(inputs.T.float(), self.input_size)\n",
    "        #print(f\"inputs.shape = {inputs.shape}\")\n",
    "        inputs_oh = one_hot_encode(inputs, self.input_size)\n",
    "        #print(f\"inputs_oh.shape = {inputs_oh.shape}\")\n",
    "        # inputs_oh = [batch_size, max_seq_length, vocab_size]\n",
    "        # pack_padded_sequence before feeding into LSTM. This is required so pytorch knows\n",
    "        # which elements of the sequence are padded ones and ignore them in computation.\n",
    "        packed_padded_inputs = pack_padded_sequence(inputs_oh, input_lengths.to(\"cpu\"), batch_first=True)\n",
    "        lstm_out_pack, (h_final, c_final) = self.lstm_layer(packed_padded_inputs)\n",
    "        # h_final and c_final = [num_direction * num_layers, batch_size, hidden_size]                \n",
    "        return h_final, c_final\n",
    "\n",
    "    # `nn.LSTM` takes a tuple of hidden states (h0, c0). h0 = initial\n",
    "    # hidden state for each element in the batch, c0 = initial cell state for each element in the batch\n",
    "    def init_state(self, batch_size):\n",
    "        return (\n",
    "            torch.zeros((self.num_directions * self.num_layers, batch_size, self.hidden_size)),\n",
    "            torch.zeros((self.num_directions * self.num_layers, batch_size, self.hidden_size))\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "class lstm_decoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, drop_out):\n",
    "        super().__init__()        \n",
    "        # since we are using one hot encoding, input_size = vocab_size\n",
    "        self.input_size = input_size        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers                \n",
    "        self.lstm_layer = nn.LSTM(\n",
    "            # as we pass in the encoder hidden state to each time step of decoder, hence input_size must account for this\n",
    "            input_size = input_size + hidden_size, \n",
    "            hidden_size = hidden_size,\n",
    "            num_layers = num_layers,\n",
    "            batch_first = True,\n",
    "            dropout = drop_out,\n",
    "            bidirectional = False\n",
    "            )   \n",
    "        self.linear = nn.Linear(input_size + hidden_size * 2, input_size)                        \n",
    "\n",
    "    def forward(self, input_oh, hidden, cell, ctx_hidden, ctx_cell):\n",
    "        # input_oh = [batch_size, target_vocab_size]\n",
    "        # ctx_hidden = [batch_size, 1, hidden_size]\n",
    "        #print(f\"decoder ctx_hidden.shape = {ctx_hidden.shape}\")\n",
    "        # The input sequence length in decoder is always 1 as we feed in one character at a time        \n",
    "        input_oh = input_oh.unsqueeze(1).to(Config.DEVICE)\n",
    "        # input_oh = [batch_size, 1, target_vocab_size]                \n",
    "        #print(f\"decoder inputs_oh.shape = {input_oh.shape}\")\n",
    "        input_ctx = torch.cat((input_oh, ctx_hidden), dim=2)\n",
    "        #print(f\"decoder inputs_ctx.shape = {input_ctx.shape}\")\n",
    "        lstm_out, (h_final, c_final) = self.lstm_layer(input_ctx, (hidden, cell))\n",
    "        #print(f\"decoder lstm_out.shape = {lstm_out.shape}\")\n",
    "        #print(f\"decoder h_final.shape = {h_final.shape}\")\n",
    "        output = torch.cat((input_oh.squeeze(1), h_final.squeeze(0), ctx_hidden.squeeze(1)), dim=1)\n",
    "        # lstm_out = [batch_size , seq_length , num_directions * hidden_size]\n",
    "        # h_final and c_final = [num_direction * num_layers, batch_size, hidden_size]\n",
    "        # seq_length and num_direction will always be 1 for decoder. Thus\n",
    "        # lstm_out = [batch_size, 1, hidden_size]\n",
    "        # h_final and c_final = [num_layers, batch_size, hidden_size]\n",
    "        pred = self.linear(output)\n",
    "        #print(f\"decoder pred.shape = {pred.shape}\")\n",
    "        # pred = [batch_size, output_dim] where output_dim = vocab_size of target sequences ( machine dates in our case)\n",
    "        # For multi class classification the number of output nodes is equal to the number of classes to predict (vocab size)\n",
    "        return pred, h_final, c_final\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder decoder model\n",
    "The hidden state returned by encoder is passed as input to each time step of the decoder in addition to the previous time step decoder hidden state and previous time step prediction or actual output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoderLitModel(pl.LightningModule):\n",
    "    def __init__(self, hparams, source_vocab_size, target_vocab_size):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.lr = hparams[\"lr\"]\n",
    "        self.weight_decay = hparams[\"weight_decay\"]\n",
    "        # target_vocab_size = vocab_size for target sequence data (machine_date) as we are using one hot encoding\n",
    "        self.target_vocab_size = target_vocab_size\n",
    "        self.encoder = lstm_encoder(\n",
    "            input_size = source_vocab_size,\n",
    "            hidden_size = hparams[\"hidden_size\"],\n",
    "            num_layers = hparams[\"num_layers\"],\n",
    "            drop_out = hparams[\"enc_drop_out\"]\n",
    "            )\n",
    "        self.decoder = lstm_decoder(\n",
    "            input_size = target_vocab_size,\n",
    "            hidden_size = hparams[\"hidden_size\"],\n",
    "            num_layers = hparams[\"num_layers\"],\n",
    "            drop_out = hparams[\"dec_drop_out\"]\n",
    "        )            \n",
    "\n",
    "    def forward(self, src_seq, src_seq_lengths, target_seq, teacher_forcing_ratio=0.5):        \n",
    "        # src_seq = [batch_size, max_source_seq_length]\n",
    "        # target_seq = [batch_size, target_seq_length]\n",
    "        target_seq_oh = one_hot_encode(target_seq, self.target_vocab_size)\n",
    "        # target_seq_oh = [batch_size, target_seq_length, target_vocab_size]\n",
    "        batch_size = target_seq_oh.shape[0]        \n",
    "        # target sequence length is 11 as it includes the <sos> token at the begining\n",
    "        target_seq_length = target_seq_oh.shape[1]            \n",
    "        # tensor to store decoder output\n",
    "        dec_outputs = torch.zeros((batch_size, target_seq_length, self.target_vocab_size))                \n",
    "        # first input to the decoder is the <sos> token which is the first character in all target sequences\n",
    "        input = target_seq_oh[:, 0, :].reshape(batch_size, -1)\n",
    "        # input = [batch_size, target_vocab_size]        \n",
    "        # last hidden and cell state of the encoder is the context which is used as initial hidden and cell state of the decoder\n",
    "        # and also passed to each time step of the decoder\n",
    "        ctx_hidden, ctx_cell = self.encoder(src_seq, src_seq_lengths)\n",
    "        hidden = ctx_hidden\n",
    "        cell = ctx_cell\n",
    "        # we want batch_size as the first dim in context (encoder final hidden state)\n",
    "        ctx_hidden = ctx_hidden.permute((1,0,2))\n",
    "        ctx_cell = ctx_cell.permute((1,0,2))\n",
    "        for t in range(1, target_seq_length):            \n",
    "            dec_output, hidden, cell = self.decoder(input, hidden, cell, ctx_hidden, ctx_cell)\n",
    "            # dec_output = [batch_size, target_vocab_size]            \n",
    "            dec_outputs[:, t, :] = dec_output\n",
    "            # whether to use teacher forcing\n",
    "            teacher_forcing = False if np.random.random() < teacher_forcing_ratio else True            \n",
    "            # if teacher forcing use actual token at t as the input to t+1, otherwise use the prediction at t\n",
    "            # as the input to t+1\n",
    "            actual_t = target_seq_oh[:, t, :]\n",
    "            input = actual_t if teacher_forcing else dec_outputs[:, t, :]\n",
    "            input = input.reshape(batch_size, -1)\n",
    "        return dec_outputs            \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        model_optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, self.parameters()), lr=self.lr, weight_decay=self.weight_decay)\n",
    "        lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(model_optimizer, mode=\"min\")\n",
    "        return {\n",
    "            \"optimizer\": model_optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": lr_scheduler,\n",
    "                \"monitor\": \"val_loss\",\n",
    "                \"frequency\": 1\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # data loader batch doesn't perform one hot encoding of either source or target sequences\n",
    "        src_padded_seq, src_seq_lengths, target_seq = batch\n",
    "        # target_seq = [batch_size, target_seq_length]\n",
    "        # src_padded_seq = [batch_size, max_src_seq_length]        \n",
    "        pred_target_seq = self(src_padded_seq, src_seq_lengths, target_seq)\n",
    "        # pred_target_seq = [batch_size, target_seq_length, target_vocab_size]\n",
    "        # we will exclude the first character from both the predicted and actual target dates. The first character\n",
    "        # in target_dates in <sos> token while the first value in pred_target_dates is 0.         \n",
    "        target_seq = target_seq[:, 1:]        \n",
    "        # flatten the target_seq to 1d \n",
    "        target_seq = target_seq.reshape(-1)\n",
    "        # [batch_size * target_seq_length]\n",
    "        pred_target_seq = pred_target_seq[:, 1:, :].to(Config.DEVICE)\n",
    "        # flatten the predicted target seq to 2d\n",
    "        pred_target_seq = pred_target_seq.view(-1, self.target_vocab_size)\n",
    "        # pred_target_seq = [batch_size * target_seq_length, target_vocab_size]\n",
    "        train_loss = cross_entropy(pred_target_seq, target_seq)\n",
    "        train_perplexity = torch.exp(train_loss)\n",
    "        self.log(\"train_loss\", train_loss, prog_bar=True, logger=True, on_step=True, on_epoch=True)\n",
    "        self.log(\"train_perplexity\", train_perplexity, prog_bar=True, logger=True, on_step=True, on_epoch=True)\n",
    "        return train_loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):        \n",
    "        src_padded_seq, src_seq_lengths, target_seq = batch        \n",
    "        # Remember to turn teacher forcing off for validation\n",
    "        pred_target_seq = self(src_padded_seq, src_seq_lengths, target_seq, teacher_forcing_ratio=0)\n",
    "        target_seq = target_seq[:, 1:].reshape(-1)\n",
    "        pred_target_seq = pred_target_seq[:, 1:, :].to(Config.DEVICE)\n",
    "        # flatten the predicted target seq to 2d\n",
    "        pred_target_seq = pred_target_seq.view(-1, self.target_vocab_size)\n",
    "        val_loss = cross_entropy(pred_target_seq, target_seq)\n",
    "        val_perplexity = torch.exp(val_loss)\n",
    "        self.log(\"val_loss\", val_loss, prog_bar=True, logger=True, on_step=True, on_epoch=True)\n",
    "        self.log(\"val_perplexity\", val_perplexity, prog_bar=True, logger=True, on_step=True, on_epoch=True)\n",
    "        return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "# For results reproducibility \n",
    "# sets seeds for numpy, torch, python.random and PYTHONHASHSEED.\n",
    "pl.seed_everything(42, workers=True)\n",
    "\n",
    "# Best trial number = 10\n",
    "# Best trial params:\n",
    "# {'lr': 0.0009729811471218791, 'hidden_size': 218, 'drop_out': 0.20683771027057984, 'num_layers': 2, 'weight_decay': 1.0661805946346311e-06}\n",
    "\n",
    "# model hyperparameters\n",
    "model_params = {    \n",
    "    \"num_layers\": 1,    \n",
    "    \"hidden_size\": 218,\n",
    "    \"enc_drop_out\": 0.206,\n",
    "    \"dec_drop_out\": 0.206,\n",
    "    \"lr\": 0.00097,\n",
    "    \"weight_decay\": 1.066e-06\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import Callback\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "# Monitor multiple metric values that are calculated either in training or validation step and return the\n",
    "# best metric values for each epoch\n",
    "class MetricsAggCallback(Callback):\n",
    "    def __init__(self, metrics_to_monitor):\n",
    "        # dictionary with metric name as key and monitor mode (min, max) as the value\n",
    "        # ( the same names used to log metric values in training and validation step)\n",
    "        self.metrics_to_monitor = metrics_to_monitor\n",
    "        # dictionary with metric_name as key and list of metric value for each epoch\n",
    "        self.metrics = {metric: [] for metric in metrics_to_monitor.keys()}\n",
    "        # dictionary with metric_name as key and the best metric value for all epochs\n",
    "        self.best_metric = {metric: None for metric in metrics_to_monitor.keys()}\n",
    "        # dictionary with metric_name as key and the epoch number with the best metric value\n",
    "        self.best_metric_epoch = {metric: None for metric in metrics_to_monitor.keys()}     \n",
    "        self.epoch_counter = 0   \n",
    "\n",
    "    def on_validation_epoch_end(self, trainer: Trainer, pl_module: LightningModule):\n",
    "        self.epoch_counter += 1\n",
    "        print(f\"For epoch {self.epoch_counter}\")            \n",
    "        for metric, mode in self.metrics_to_monitor.items():\n",
    "            metric_value = round(trainer.callback_metrics[metric].cpu().detach().item(), 4)            \n",
    "            print(f\"{metric} = {metric_value}\")\n",
    "            self.metrics[metric].append(metric_value)\n",
    "            if mode == \"max\":\n",
    "                self.best_metric[metric] = max(self.metrics[metric])            \n",
    "            elif mode == \"min\":            \n",
    "                self.best_metric[metric] = min(self.metrics[metric])            \n",
    "            self.best_metric_epoch[metric] = self.metrics[metric].index(self.best_metric[metric])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(fold, fold_loss, fold_metrics, dl_train, dl_val, h_vocab, m_vocab, find_lr=True):\n",
    "    fold_str = f\"fold{fold}\"\n",
    "    print(f\"Running training for {fold_str}\")\n",
    "    seq2seq_model = EncoderDecoderLitModel(\n",
    "        hparams = model_params, \n",
    "        source_vocab_size = len(h_vocab),\n",
    "        target_vocab_size = len(m_vocab)\n",
    "        )\n",
    "    tb_logger = pl.loggers.TensorBoardLogger(save_dir=\"logs\")    \n",
    "    chkpt_file_name = \"best_model_{epoch}_{val_loss:.4f}\"\n",
    "    metrics_to_monitor = {\n",
    "        \"val_loss\": \"min\",\n",
    "        \"val_perplexity\": \"min\",\n",
    "        }\n",
    "    loss_chkpt_callback = ModelCheckpoint(dirpath=\"./model\", verbose=True, monitor=\"val_loss\", mode=\"min\", filename=chkpt_file_name)    \n",
    "    metric_chkpt_callback = MetricsAggCallback(metrics_to_monitor = metrics_to_monitor)\n",
    "    early_stopping_callback = EarlyStopping(monitor=\"val_loss\", patience=Config.PATIENCE, mode=\"min\", verbose=True)\n",
    "    trainer = pl.Trainer(\n",
    "        gpus = 1,\n",
    "        deterministic = True,\n",
    "        auto_select_gpus = True,\n",
    "        progress_bar_refresh_rate = 20,\n",
    "        max_epochs = Config.NUM_EPOCHS,\n",
    "        logger = tb_logger,\n",
    "        auto_lr_find = True,    \n",
    "        precision = Config.PRECISION,   \n",
    "        fast_dev_run = Config.FAST_DEV_RUN, \n",
    "        gradient_clip_val = 1.0,\n",
    "        #resume_from_checkpoint = \"model/best_model_epoch=71_val_loss=0.4772.ckpt\",\n",
    "        callbacks = [loss_chkpt_callback, metric_chkpt_callback, early_stopping_callback]\n",
    "    )        \n",
    "    if find_lr:\n",
    "        trainer.tune(model=seq2seq_model, train_dataloaders=dl_train)\n",
    "        print(seq2seq_model.lr)\n",
    "    trainer.fit(seq2seq_model, train_dataloaders=dl_train, val_dataloaders=dl_val)\n",
    "    fold_min_loss = loss_chkpt_callback.best_model_score.cpu().detach().item()\n",
    "    fold_loss.append(fold_min_loss)\n",
    "    fold_metrics = {metric: (metric_chkpt_callback.best_metric[metric], metric_chkpt_callback.best_metric_epoch[metric]) \n",
    "                    for metric in metrics_to_monitor.keys()}\n",
    "    print(f\"Best metric value for {fold_str}\")\n",
    "    print(f\"val_loss  = {fold_loss[fold]}\")\n",
    "    print(fold_metrics)\n",
    "    del trainer, seq2seq_model, loss_chkpt_callback, metric_chkpt_callback "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "\n",
    "def run_hparam_tuning(model_params, trial):\n",
    "    dl_train, dl_val, ds_train, ds_val, h_vocab, m_vocab, inv_h_vocab, inv_m_vocab = get_fold_dls(0, df_dates)\n",
    "    early_stopping = PyTorchLightningPruningCallback(trial, monitor=\"val_loss\")    \n",
    "    seq2seq_model = EncoderDecoderLitModel(\n",
    "        hparams = model_params, \n",
    "        source_vocab_size = len(h_vocab),\n",
    "        target_vocab_size = len(m_vocab)\n",
    "        )    \n",
    "    trainer = pl.Trainer(\n",
    "        checkpoint_callback=False,        \n",
    "        gpus=1,\n",
    "        # For results reproducibility \n",
    "        deterministic=True,\n",
    "        auto_select_gpus=True,\n",
    "        progress_bar_refresh_rate=20,\n",
    "        max_epochs=Config.NUM_EPOCHS,        \n",
    "        precision=Config.PRECISION,   \n",
    "        weights_summary=None,         \n",
    "        gradient_clip_val = 1.0,            \n",
    "        callbacks=[early_stopping]\n",
    "    )      \n",
    "    trainer.fit(seq2seq_model, train_dataloaders=dl_train, val_dataloaders=dl_val)     \n",
    "    loss = trainer.callback_metrics[\"val_loss\"].item()\n",
    "    del trainer, seq2seq_model, early_stopping, dl_train, dl_val\n",
    "    return loss "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning using optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import optuna\n",
    "\n",
    "# Config.NUM_EPOCHS = 20        \n",
    "# def objective(trial):\n",
    "#     params = {\n",
    "#         \"lr\": trial.suggest_loguniform(\"lr\", 1e-6, 1e-3),\n",
    "#         \"hidden_size\": trial.suggest_int(\"hidden_size\", 32, 512),\n",
    "#         \"enc_drop_out\": trial.suggest_uniform(\"enc_drop_out\", 0.2, 0.7),\n",
    "#         \"dec_drop_out\": trial.suggest_uniform(\"dec_drop_out\", 0.2, 0.7),\n",
    "#         \"num_layers\": trial.suggest_int(\"num_layers\", 1, 2),\n",
    "#         \"weight_decay\": trial.suggest_loguniform(\"weight_decay\", 1e-6, 1e-2),\n",
    "#     }    \n",
    "#     loss = run_hparam_tuning(params, trial)\n",
    "#     return loss\n",
    "\n",
    "# study = optuna.create_study(direction=\"minimize\", study_name=\"Seq2SeqModelTuning\")    \n",
    "# study.optimize(objective, n_trials=20)\n",
    "# print(f\"Best trial number = {study.best_trial.number}\")\n",
    "# print(\"Best trial params:\")\n",
    "# print(study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running training for fold0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bk_anupam/anaconda3/envs/fastai/lib/python3.9/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.206 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "/home/bk_anupam/anaconda3/envs/fastai/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:446: UserWarning: Checkpoint directory ./model exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "Using native 16bit precision.\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type         | Params\n",
      "-----------------------------------------\n",
      "0 | encoder | lstm_encoder | 231 K \n",
      "1 | decoder | lstm_decoder | 397 K \n",
      "-----------------------------------------\n",
      "629 K     Trainable params\n",
      "0         Non-trainable params\n",
      "629 K     Total params\n",
      "2.519     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4309710eb0d442db4815b006548ee01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "For epoch 1\n",
      "val_loss = 2.4857\n",
      "val_perplexity = 12.0097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bk_anupam/anaconda3/envs/fastai/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:326: UserWarning: The number of training samples (47) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7510b67131849528e72a19c4d3c681a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: -1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n",
      "decoder ctx_hidden.shape = torch.Size([2048, 1, 218])\n",
      "decoder inputs_oh.shape = torch.Size([2048, 1, 12])\n",
      "decoder inputs_ctx.shape = torch.Size([2048, 1, 230])\n",
      "decoder lstm_out.shape = torch.Size([2048, 1, 218])\n",
      "decoder h_final.shape = torch.Size([1, 2048, 218])\n",
      "decoder pred.shape = torch.Size([2048, 12])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bk_anupam/anaconda3/envs/fastai/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1051: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'cpu'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15826/2614573196.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNUM_FOLDS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdl_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_vocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_vocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minv_h_vocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minv_m_vocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_fold_dls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_dates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mrun_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold_metrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_vocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_vocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfind_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_15826/3872600288.py\u001b[0m in \u001b[0;36mrun_training\u001b[0;34m(fold, fold_loss, fold_metrics, dl_train, dl_val, h_vocab, m_vocab, find_lr)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq2seq_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq2seq_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdl_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdl_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mfold_min_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_chkpt_callback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_model_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mfold_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold_min_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     fold_metrics = {metric: (metric_chkpt_callback.best_metric[metric], metric_chkpt_callback.best_metric_epoch[metric]) \n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'cpu'"
     ]
    }
   ],
   "source": [
    "find_lr = True\n",
    "fold_loss = []\n",
    "fold_metrics = []\n",
    "\n",
    "for fold in range(Config.NUM_FOLDS):\n",
    "    dl_train, dl_val, ds_train, ds_val, h_vocab, m_vocab, inv_h_vocab, inv_m_vocab = get_fold_dls(fold, df_dates)\n",
    "    run_training(fold, fold_loss, fold_metrics, dl_train, dl_val, h_vocab, m_vocab, find_lr=False)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key_from_value(dict, value_to_search):\n",
    "    for key, value in dict.items():\n",
    "        if value == value_to_search:\n",
    "            return key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference on test set\n",
    "\n",
    "def run_prediction():\n",
    "    test_dataset = load_date_dataset(num_examples=10)\n",
    "    Config.BATCH_SIZE = 1\n",
    "    df_dates_test = pd.DataFrame({\"h_dt\": test_dataset[:, 0], \"m_dt\": test_dataset[:, 1]})\n",
    "    h_dt_max_len = df_dates_test.h_dt.apply(lambda x: len(x)).max()\n",
    "    transform = StoITensorTransform(h_vocab, h_dt_max_len)\n",
    "    target_transform = StoITensorTransform(m_vocab, len(m_vocab), add_sos_token=True)\n",
    "    ds_test = DateDataset(df_dates_test.h_dt, df_dates_test.m_dt, transform=transform, target_transform=target_transform)    \n",
    "    dl_test = DataLoader(ds_test, batch_size=Config.BATCH_SIZE, num_workers=Config.NUM_WORKERS, collate_fn=pad_collate)\n",
    "    seq2seq_model = EncoderDecoderLitModel.load_from_checkpoint(\n",
    "        checkpoint_path = \"model/best_model_epoch=91_val_loss=0.4555.ckpt\",\n",
    "        hparams = model_params, \n",
    "        source_vocab_size = len(h_vocab),\n",
    "        target_vocab_size = len(m_vocab)\n",
    "    ).to(Config.DEVICE)\n",
    "    pred_table = []\n",
    "    for src_seq, src_seq_len, target_seq in dl_test:        \n",
    "        src_seq = src_seq.to(Config.DEVICE)\n",
    "        src_seq_len = src_seq_len.to(Config.DEVICE)\n",
    "        target_seq = target_seq.to(Config.DEVICE)\n",
    "        target_seq_oh = one_hot_encode(target_seq, len(m_vocab))\n",
    "        outputs = seq2seq_model(src_seq, src_seq_len, target_seq_oh)\n",
    "        pred_target_seq = outputs.argmax(2)[:, 1:].reshape(-1).cpu().tolist()\n",
    "        target_seq = target_seq[:, 1:].reshape(-1).cpu().tolist()                \n",
    "        src_seq = src_seq.reshape(-1).cpu().tolist()\n",
    "        source_str = ''.join([get_key_from_value(h_vocab, index) for index in src_seq])                \n",
    "        target_str = ''.join([inv_m_vocab[index] for index in target_seq])        \n",
    "        pred_target_str = ''.join([get_key_from_value(m_vocab, index) for index in pred_target_seq])        \n",
    "        pred_table.append([source_str, target_str, pred_target_str])        \n",
    "    return pred_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "pred_table = run_prediction()    \n",
    "header = [\"Source sequence\", \"Target Sequence\", \"Predicted Target Sequence\"]\n",
    "print(tabulate(pred_table, headers=header))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0197751694b00855cd01780d565fa2e16f7945f624c4146f8d6aac863c2ba178"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('fastai': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
